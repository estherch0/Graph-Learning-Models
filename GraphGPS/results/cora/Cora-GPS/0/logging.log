[*] Run ID 0: seed=0, split_index=0
    Starting now: 2024-12-02 23:17:12.031154
[*] Loaded dataset 'Cora' from 'PyG':
  Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
  undirected: True
  num graphs: 1
  avg num_nodes/graph: 2708
  num node features: 1433
  num edge features: 0
  num classes: 7
Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
  ...estimated to be undirected: True
Done! Took 00:00:05.17
GraphGymModule(
  (model): GPSModel(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=1433, out_features=56, bias=True)
        (linear_A): Linear(in_features=2, out_features=16, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=16, out_features=8, bias=True)
          (2): ReLU()
        )
      )
    )
    (layers): Sequential(
      (0): GPSLayer(
        summary: dim_h=64, local_gnn_type=GCN, global_model_type=Transformer, heads=4
        (local_model): GCNConv(64, 64)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.1, inplace=False)
        (dropout_attn): Dropout(p=0.1, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.1, inplace=False)
        (ff_dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): GPSLayer(
        summary: dim_h=64, local_gnn_type=GCN, global_model_type=Transformer, heads=4
        (local_model): GCNConv(64, 64)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.1, inplace=False)
        (dropout_attn): Dropout(p=0.1, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.1, inplace=False)
        (ff_dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): GPSLayer(
        summary: dim_h=64, local_gnn_type=GCN, global_model_type=Transformer, heads=4
        (local_model): GCNConv(64, 64)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.1, inplace=False)
        (dropout_attn): Dropout(p=0.1, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.1, inplace=False)
        (ff_dropout2): Dropout(p=0.1, inplace=False)
      )
      (3): GPSLayer(
        summary: dim_h=64, local_gnn_type=GCN, global_model_type=Transformer, heads=4
        (local_model): GCNConv(64, 64)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.1, inplace=False)
        (dropout_attn): Dropout(p=0.1, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.1, inplace=False)
        (ff_dropout2): Dropout(p=0.1, inplace=False)
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 7, bias=True)
          )
        )
      )
    )
  )
)
accelerator: cpu
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 128
  edge_encoder: False
  edge_encoder_bn: False
  edge_encoder_name: DummyEdge
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: PyG
  infer_link_label: None
  label_column: none
  label_table: none
  location: local
  name: Cora
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: LapPE
  node_encoder_num_types: 0
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: node
  task_type: classification
  to_undirected: False
  transductive: True
  transform: none
  tu_simple: True
devices: None
example_arg: example
example_group:
  example_arg: example
gnn:
  act: relu
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: True
  clear_feature: True
  dim_inner: 64
  dropout: 0.0
  head: inductive_node
  keep_edge: 0.5
  l2norm: True
  layer_type: generalconv
  layers_mp: 2
  layers_post_mp: 3
  layers_pre_mp: 0
  msg_direction: single
  normalize_adj: False
  residual: False
  self_msg: concat
  skip_every: 1
  stage_type: stack
gpu_mem: False
graphormer:
  attention_dropout: 0.0
  dropout: 0.0
  embed_dim: 80
  input_dropout: 0.0
  mlp_dropout: 0.0
  num_heads: 4
  num_layers: 6
  use_graph_token: False
gt:
  attn_dropout: 0.1
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  dim_hidden: 64
  dropout: 0.1
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: GCN+Transformer
  layers: 4
  n_heads: 4
  pna_degrees: []
  residual: True
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy
model:
  edge_decoding: dot
  graph_pooling: add
  loss_fun: cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: GPSModel
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.0005
  batch_accumulation: 1
  clip_grad_norm: True
  clip_grad_norm_value: 1.0
  lr_decay: 0.1
  max_epoch: 100
  min_lr: 0.0
  momentum: 0.9
  num_warmup_epochs: 10
  optimizer: adamW
  reduce_factor: 0.1
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  weight_decay: 0.0
out_dir: results/cora/Cora-GPS
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_GraphormerBias:
  dim_pe: 0
  enable: False
  node_degrees_only: True
  num_in_degrees: 13
  num_out_degrees: 105
  num_spatial_types: 20
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 8
  eigen:
    eigvec_norm: L2
    laplacian_norm: none
    max_freqs: 10
  enable: True
  layers: 2
  model: DeepSet
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_RWSE:
  dim_pe: 16
  enable: True
  kernel:
    times: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
    times_func: range(1,17)
  layers: 3
  model: Linear
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: BatchNorm
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: True
print: both
round: 5
run_dir: results/cora/Cora-GPS/0
run_id: 0
run_multiple_splits: []
seed: 0
share:
  dim_in: 1433
  dim_out: 7
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: False
train:
  auto_resume: False
  batch_size: 32
  ckpt_best: False
  ckpt_clean: True
  ckpt_period: 100
  enable_ckpt: False
  epoch_resume: -1
  eval_period: 5
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: gtransformers
  name: 
  project: cora-GPS
  use: False
Num parameters: 240303
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 2.14754, 'eta': 212.60619, 'eta_hours': 0.05906, 'loss': 1.95673811, 'lr': 0.0, 'params': 240303, 'time_iter': 2.14754, 'accuracy': 0.10044, 'f1': 0.07798, 'auc': 0.48079}
...computing epoch stats took: 0.02s
val: {'epoch': 0, 'time_epoch': 0.5934, 'loss': 1.95882177, 'lr': 0, 'params': 240303, 'time_iter': 0.5934, 'accuracy': 0.06647, 'f1': 0.01783, 'auc': 0.52091}
...computing epoch stats took: 0.01s
test: {'epoch': 0, 'time_epoch': 0.51378, 'loss': 1.95882177, 'lr': 0, 'params': 240303, 'time_iter': 0.51378, 'accuracy': 0.06647, 'f1': 0.01783, 'auc': 0.52091}
...computing epoch stats took: 0.01s
> Epoch 0: took 3.3s (avg 3.3s) | Best so far: epoch 0	train_loss: 1.9567 train_accuracy: 0.1004	val_loss: 1.9588 val_accuracy: 0.0665	test_loss: 1.9588 test_accuracy: 0.0665
train: {'epoch': 1, 'time_epoch': 1.99452, 'eta': 202.96101, 'eta_hours': 0.05638, 'loss': 1.9560231, 'lr': 5e-05, 'params': 240303, 'time_iter': 1.99452, 'accuracy': 0.10561, 'f1': 0.08111, 'auc': 0.48813}
...computing epoch stats took: 0.01s
train: {'epoch': 2, 'time_epoch': 1.98391, 'eta': 198.07295, 'eta_hours': 0.05502, 'loss': 1.9552747, 'lr': 0.0001, 'params': 240303, 'time_iter': 1.98391, 'accuracy': 0.10709, 'f1': 0.08035, 'auc': 0.49061}
...computing epoch stats took: 0.01s
train: {'epoch': 3, 'time_epoch': 2.03039, 'eta': 195.75251, 'eta_hours': 0.05438, 'loss': 1.95294833, 'lr': 0.00015, 'params': 240303, 'time_iter': 2.03039, 'accuracy': 0.10524, 'f1': 0.08126, 'auc': 0.50936}
train: {'epoch': 4, 'time_epoch': 2.14049, 'eta': 195.64008, 'eta_hours': 0.05434, 'loss': 1.94974458, 'lr': 0.0002, 'params': 240303, 'time_iter': 2.14049, 'accuracy': 0.12888, 'f1': 0.09884, 'auc': 0.52905}
val: {'epoch': 4, 'time_epoch': 0.64043, 'loss': 1.95196235, 'lr': 0, 'params': 240303, 'time_iter': 0.64043, 'accuracy': 0.06832, 'f1': 0.02156, 'auc': 0.5323}
test: {'epoch': 4, 'time_epoch': 0.52244, 'loss': 1.95196235, 'lr': 0, 'params': 240303, 'time_iter': 0.52244, 'accuracy': 0.06832, 'f1': 0.02156, 'auc': 0.5323}
> Epoch 4: took 3.3s (avg 2.5s) | Best so far: epoch 4	train_loss: 1.9497 train_accuracy: 0.1289	val_loss: 1.9520 val_accuracy: 0.0683	test_loss: 1.9520 test_accuracy: 0.0683
train: {'epoch': 5, 'time_epoch': 2.00709, 'eta': 192.76164, 'eta_hours': 0.05354, 'loss': 1.94671857, 'lr': 0.00025, 'params': 240303, 'time_iter': 2.00709, 'accuracy': 0.14365, 'f1': 0.1112, 'auc': 0.54648}
train: {'epoch': 6, 'time_epoch': 2.1435, 'eta': 191.9445, 'eta_hours': 0.05332, 'loss': 1.94145548, 'lr': 0.0003, 'params': 240303, 'time_iter': 2.1435, 'accuracy': 0.16359, 'f1': 0.12555, 'auc': 0.57835}
train: {'epoch': 7, 'time_epoch': 2.66897, 'eta': 196.83864, 'eta_hours': 0.05468, 'loss': 1.93529284, 'lr': 0.00035, 'params': 240303, 'time_iter': 2.66897, 'accuracy': 0.19941, 'f1': 0.15303, 'auc': 0.61262}
train: {'epoch': 8, 'time_epoch': 2.0443, 'eta': 193.73603, 'eta_hours': 0.05382, 'loss': 1.92810094, 'lr': 0.0004, 'params': 240303, 'time_iter': 2.0443, 'accuracy': 0.24335, 'f1': 0.1844, 'auc': 0.64962}
train: {'epoch': 9, 'time_epoch': 2.00273, 'eta': 190.47088, 'eta_hours': 0.05291, 'loss': 1.91972101, 'lr': 0.00045, 'params': 240303, 'time_iter': 2.00273, 'accuracy': 0.29801, 'f1': 0.22221, 'auc': 0.69223}
val: {'epoch': 9, 'time_epoch': 0.56984, 'loss': 1.93910694, 'lr': 0, 'params': 240303, 'time_iter': 0.56984, 'accuracy': 0.16581, 'f1': 0.12514, 'auc': 0.67978}
test: {'epoch': 9, 'time_epoch': 0.53428, 'loss': 1.93910694, 'lr': 0, 'params': 240303, 'time_iter': 0.53428, 'accuracy': 0.16581, 'f1': 0.12514, 'auc': 0.67978}
> Epoch 9: took 3.1s (avg 2.5s) | Best so far: epoch 9	train_loss: 1.9197 train_accuracy: 0.2980	val_loss: 1.9391 val_accuracy: 0.1658	test_loss: 1.9391 test_accuracy: 0.1658
train: {'epoch': 10, 'time_epoch': 1.98282, 'eta': 187.27419, 'eta_hours': 0.05202, 'loss': 1.90955389, 'lr': 0.0005, 'params': 240303, 'time_iter': 1.98282, 'accuracy': 0.35598, 'f1': 0.25742, 'auc': 0.7358}
train: {'epoch': 11, 'time_epoch': 2.03676, 'eta': 184.6754, 'eta_hours': 0.0513, 'loss': 1.89952338, 'lr': 0.00049985, 'params': 240303, 'time_iter': 2.03676, 'accuracy': 0.41507, 'f1': 0.29716, 'auc': 0.76658}
train: {'epoch': 12, 'time_epoch': 2.02397, 'eta': 182.07749, 'eta_hours': 0.05058, 'loss': 1.88816106, 'lr': 0.00049939, 'params': 240303, 'time_iter': 2.02397, 'accuracy': 0.46898, 'f1': 0.34236, 'auc': 0.79495}
train: {'epoch': 13, 'time_epoch': 2.03217, 'eta': 179.61194, 'eta_hours': 0.04989, 'loss': 1.87510908, 'lr': 0.00049863, 'params': 240303, 'time_iter': 2.03217, 'accuracy': 0.50222, 'f1': 0.36821, 'auc': 0.83662}
train: {'epoch': 14, 'time_epoch': 2.2045, 'eta': 178.18071, 'eta_hours': 0.04949, 'loss': 1.86616516, 'lr': 0.00049757, 'params': 240303, 'time_iter': 2.2045, 'accuracy': 0.53471, 'f1': 0.39489, 'auc': 0.8572}
val: {'epoch': 14, 'time_epoch': 0.71494, 'loss': 1.90522552, 'lr': 0, 'params': 240303, 'time_iter': 0.71494, 'accuracy': 0.44387, 'f1': 0.28192, 'auc': 0.8185}
test: {'epoch': 14, 'time_epoch': 0.6005, 'loss': 1.90522552, 'lr': 0, 'params': 240303, 'time_iter': 0.6005, 'accuracy': 0.44387, 'f1': 0.28192, 'auc': 0.8185}
> Epoch 14: took 3.6s (avg 2.4s) | Best so far: epoch 14	train_loss: 1.8662 train_accuracy: 0.5347	val_loss: 1.9052 val_accuracy: 0.4439	test_loss: 1.9052 test_accuracy: 0.4439
train: {'epoch': 15, 'time_epoch': 2.13688, 'eta': 176.29783, 'eta_hours': 0.04897, 'loss': 1.85330129, 'lr': 0.0004962, 'params': 240303, 'time_iter': 2.13688, 'accuracy': 0.56352, 'f1': 0.41339, 'auc': 0.88274}
train: {'epoch': 16, 'time_epoch': 2.09993, 'eta': 174.20466, 'eta_hours': 0.04839, 'loss': 1.84412038, 'lr': 0.00049454, 'params': 240303, 'time_iter': 2.09993, 'accuracy': 0.56425, 'f1': 0.39883, 'auc': 0.89131}
train: {'epoch': 17, 'time_epoch': 2.00764, 'eta': 171.69028, 'eta_hours': 0.04769, 'loss': 1.83299804, 'lr': 0.00049257, 'params': 240303, 'time_iter': 2.00764, 'accuracy': 0.58087, 'f1': 0.39039, 'auc': 0.90781}
train: {'epoch': 18, 'time_epoch': 1.99725, 'eta': 169.18496, 'eta_hours': 0.047, 'loss': 1.82337105, 'lr': 0.00049032, 'params': 240303, 'time_iter': 1.99725, 'accuracy': 0.58863, 'f1': 0.39432, 'auc': 0.91663}
train: {'epoch': 19, 'time_epoch': 1.98288, 'eta': 166.67298, 'eta_hours': 0.0463, 'loss': 1.81261885, 'lr': 0.00048776, 'params': 240303, 'time_iter': 1.98288, 'accuracy': 0.5938, 'f1': 0.38338, 'auc': 0.9247}
val: {'epoch': 19, 'time_epoch': 0.62581, 'loss': 1.83796489, 'lr': 0, 'params': 240303, 'time_iter': 0.62581, 'accuracy': 0.50665, 'f1': 0.29844, 'auc': 0.90535}
test: {'epoch': 19, 'time_epoch': 0.55044, 'loss': 1.83796489, 'lr': 0, 'params': 240303, 'time_iter': 0.55044, 'accuracy': 0.50665, 'f1': 0.29844, 'auc': 0.90535}
> Epoch 19: took 3.2s (avg 2.4s) | Best so far: epoch 19	train_loss: 1.8126 train_accuracy: 0.5938	val_loss: 1.8380 val_accuracy: 0.5067	test_loss: 1.8380 test_accuracy: 0.5067
train: {'epoch': 20, 'time_epoch': 2.05632, 'eta': 164.48765, 'eta_hours': 0.04569, 'loss': 1.80409324, 'lr': 0.00048492, 'params': 240303, 'time_iter': 2.05632, 'accuracy': 0.59749, 'f1': 0.38617, 'auc': 0.92988}
train: {'epoch': 21, 'time_epoch': 1.99809, 'eta': 162.10758, 'eta_hours': 0.04503, 'loss': 1.79346192, 'lr': 0.0004818, 'params': 240303, 'time_iter': 1.99809, 'accuracy': 0.59934, 'f1': 0.38306, 'auc': 0.94229}
train: {'epoch': 22, 'time_epoch': 1.99313, 'eta': 159.74414, 'eta_hours': 0.04437, 'loss': 1.78430939, 'lr': 0.00047839, 'params': 240303, 'time_iter': 1.99313, 'accuracy': 0.61558, 'f1': 0.4033, 'auc': 0.94459}
train: {'epoch': 23, 'time_epoch': 2.06147, 'eta': 157.62797, 'eta_hours': 0.04379, 'loss': 1.7760601, 'lr': 0.0004747, 'params': 240303, 'time_iter': 2.06147, 'accuracy': 0.61891, 'f1': 0.40186, 'auc': 0.94457}
train: {'epoch': 24, 'time_epoch': 1.99469, 'eta': 155.31582, 'eta_hours': 0.04314, 'loss': 1.76775575, 'lr': 0.00047074, 'params': 240303, 'time_iter': 1.99469, 'accuracy': 0.61891, 'f1': 0.39949, 'auc': 0.95131}
val: {'epoch': 24, 'time_epoch': 0.55693, 'loss': 1.78699148, 'lr': 0, 'params': 240303, 'time_iter': 0.55693, 'accuracy': 0.52363, 'f1': 0.32241, 'auc': 0.93854}
test: {'epoch': 24, 'time_epoch': 0.57737, 'loss': 1.78699148, 'lr': 0, 'params': 240303, 'time_iter': 0.57737, 'accuracy': 0.52363, 'f1': 0.32241, 'auc': 0.93854}
> Epoch 24: took 3.2s (avg 2.4s) | Best so far: epoch 24	train_loss: 1.7678 train_accuracy: 0.6189	val_loss: 1.7870 val_accuracy: 0.5236	test_loss: 1.7870 test_accuracy: 0.5236
train: {'epoch': 25, 'time_epoch': 2.87706, 'eta': 155.53946, 'eta_hours': 0.04321, 'loss': 1.75870931, 'lr': 0.00046651, 'params': 240303, 'time_iter': 2.87706, 'accuracy': 0.62814, 'f1': 0.41098, 'auc': 0.95383}
train: {'epoch': 26, 'time_epoch': 2.33797, 'eta': 154.07588, 'eta_hours': 0.0428, 'loss': 1.75071347, 'lr': 0.00046201, 'params': 240303, 'time_iter': 2.33797, 'accuracy': 0.63516, 'f1': 0.41871, 'auc': 0.95811}
train: {'epoch': 27, 'time_epoch': 2.19784, 'eta': 152.18951, 'eta_hours': 0.04227, 'loss': 1.74181008, 'lr': 0.00045726, 'params': 240303, 'time_iter': 2.19784, 'accuracy': 0.64402, 'f1': 0.43232, 'auc': 0.96114}
train: {'epoch': 28, 'time_epoch': 4.38354, 'eta': 155.63286, 'eta_hours': 0.04323, 'loss': 1.73454392, 'lr': 0.00045225, 'params': 240303, 'time_iter': 4.38354, 'accuracy': 0.6514, 'f1': 0.44205, 'auc': 0.96175}
train: {'epoch': 29, 'time_epoch': 2.27484, 'eta': 153.63412, 'eta_hours': 0.04268, 'loss': 1.7274226, 'lr': 0.000447, 'params': 240303, 'time_iter': 2.27484, 'accuracy': 0.65362, 'f1': 0.44212, 'auc': 0.96502}
val: {'epoch': 29, 'time_epoch': 0.59241, 'loss': 1.74188888, 'lr': 0, 'params': 240303, 'time_iter': 0.59241, 'accuracy': 0.5757, 'f1': 0.37745, 'auc': 0.9554}
test: {'epoch': 29, 'time_epoch': 0.60049, 'loss': 1.74188888, 'lr': 0, 'params': 240303, 'time_iter': 0.60049, 'accuracy': 0.5757, 'f1': 0.37745, 'auc': 0.9554}
> Epoch 29: took 3.5s (avg 2.5s) | Best so far: epoch 29	train_loss: 1.7274 train_accuracy: 0.6536	val_loss: 1.7419 val_accuracy: 0.5757	test_loss: 1.7419 test_accuracy: 0.5757
train: {'epoch': 30, 'time_epoch': 2.00107, 'eta': 151.0082, 'eta_hours': 0.04195, 'loss': 1.71922112, 'lr': 0.00044151, 'params': 240303, 'time_iter': 2.00107, 'accuracy': 0.661, 'f1': 0.45946, 'auc': 0.96787}
train: {'epoch': 31, 'time_epoch': 2.04575, 'eta': 148.51629, 'eta_hours': 0.04125, 'loss': 1.71257269, 'lr': 0.00043579, 'params': 240303, 'time_iter': 2.04575, 'accuracy': 0.6562, 'f1': 0.45404, 'auc': 0.97024}
train: {'epoch': 32, 'time_epoch': 1.99747, 'eta': 145.95339, 'eta_hours': 0.04054, 'loss': 1.70420074, 'lr': 0.00042983, 'params': 240303, 'time_iter': 1.99747, 'accuracy': 0.67725, 'f1': 0.47956, 'auc': 0.9726}
train: {'epoch': 33, 'time_epoch': 1.98736, 'eta': 143.40412, 'eta_hours': 0.03983, 'loss': 1.69896364, 'lr': 0.00042366, 'params': 240303, 'time_iter': 1.98736, 'accuracy': 0.67725, 'f1': 0.48562, 'auc': 0.97059}
train: {'epoch': 34, 'time_epoch': 2.00338, 'eta': 140.91671, 'eta_hours': 0.03914, 'loss': 1.6920501, 'lr': 0.00041728, 'params': 240303, 'time_iter': 2.00338, 'accuracy': 0.68131, 'f1': 0.48342, 'auc': 0.97338}
val: {'epoch': 34, 'time_epoch': 0.58609, 'loss': 1.69705141, 'lr': 0, 'params': 240303, 'time_iter': 0.58609, 'accuracy': 0.63959, 'f1': 0.4658, 'auc': 0.97263}
test: {'epoch': 34, 'time_epoch': 0.556, 'loss': 1.69705141, 'lr': 0, 'params': 240303, 'time_iter': 0.556, 'accuracy': 0.63959, 'f1': 0.4658, 'auc': 0.97263}
> Epoch 34: took 3.2s (avg 2.5s) | Best so far: epoch 34	train_loss: 1.6921 train_accuracy: 0.6813	val_loss: 1.6971 val_accuracy: 0.6396	test_loss: 1.6971 test_accuracy: 0.6396
train: {'epoch': 35, 'time_epoch': 1.98099, 'eta': 138.41639, 'eta_hours': 0.03845, 'loss': 1.6858561, 'lr': 0.0004107, 'params': 240303, 'time_iter': 1.98099, 'accuracy': 0.69092, 'f1': 0.50387, 'auc': 0.97557}
train: {'epoch': 36, 'time_epoch': 2.02819, 'eta': 136.02451, 'eta_hours': 0.03778, 'loss': 1.68035448, 'lr': 0.00040392, 'params': 240303, 'time_iter': 2.02819, 'accuracy': 0.70458, 'f1': 0.5313, 'auc': 0.97587}
train: {'epoch': 37, 'time_epoch': 2.048, 'eta': 133.68409, 'eta_hours': 0.03713, 'loss': 1.67316389, 'lr': 0.00039695, 'params': 240303, 'time_iter': 2.048, 'accuracy': 0.71861, 'f1': 0.54876, 'auc': 0.97722}
train: {'epoch': 38, 'time_epoch': 2.01056, 'eta': 131.30011, 'eta_hours': 0.03647, 'loss': 1.66829979, 'lr': 0.0003898, 'params': 240303, 'time_iter': 2.01056, 'accuracy': 0.72895, 'f1': 0.57344, 'auc': 0.97914}
train: {'epoch': 39, 'time_epoch': 1.97955, 'eta': 128.88829, 'eta_hours': 0.0358, 'loss': 1.66200769, 'lr': 0.00038248, 'params': 240303, 'time_iter': 1.97955, 'accuracy': 0.74889, 'f1': 0.6065, 'auc': 0.98031}
val: {'epoch': 39, 'time_epoch': 0.59845, 'loss': 1.65835893, 'lr': 0, 'params': 240303, 'time_iter': 0.59845, 'accuracy': 0.73855, 'f1': 0.61569, 'auc': 0.9821}
test: {'epoch': 39, 'time_epoch': 0.53122, 'loss': 1.65835893, 'lr': 0, 'params': 240303, 'time_iter': 0.53122, 'accuracy': 0.73855, 'f1': 0.61569, 'auc': 0.9821}
> Epoch 39: took 3.1s (avg 2.4s) | Best so far: epoch 39	train_loss: 1.6620 train_accuracy: 0.7489	val_loss: 1.6584 val_accuracy: 0.7386	test_loss: 1.6584 test_accuracy: 0.7386
train: {'epoch': 40, 'time_epoch': 2.04487, 'eta': 126.59154, 'eta_hours': 0.03516, 'loss': 1.6565702, 'lr': 0.000375, 'params': 240303, 'time_iter': 2.04487, 'accuracy': 0.75074, 'f1': 0.61712, 'auc': 0.98132}
train: {'epoch': 41, 'time_epoch': 2.3305, 'eta': 124.70123, 'eta_hours': 0.03464, 'loss': 1.65144455, 'lr': 0.00036737, 'params': 240303, 'time_iter': 2.3305, 'accuracy': 0.76403, 'f1': 0.63862, 'auc': 0.98334}
train: {'epoch': 42, 'time_epoch': 2.16788, 'eta': 122.57488, 'eta_hours': 0.03405, 'loss': 1.64613509, 'lr': 0.00035959, 'params': 240303, 'time_iter': 2.16788, 'accuracy': 0.78767, 'f1': 0.6701, 'auc': 0.98331}
train: {'epoch': 43, 'time_epoch': 2.00839, 'eta': 120.24366, 'eta_hours': 0.0334, 'loss': 1.64148223, 'lr': 0.00035168, 'params': 240303, 'time_iter': 2.00839, 'accuracy': 0.80945, 'f1': 0.69677, 'auc': 0.98319}
train: {'epoch': 44, 'time_epoch': 2.00721, 'eta': 117.92535, 'eta_hours': 0.03276, 'loss': 1.63663042, 'lr': 0.00034365, 'params': 240303, 'time_iter': 2.00721, 'accuracy': 0.81499, 'f1': 0.70548, 'auc': 0.98435}
val: {'epoch': 44, 'time_epoch': 0.58867, 'loss': 1.63215494, 'lr': 0, 'params': 240303, 'time_iter': 0.58867, 'accuracy': 0.82275, 'f1': 0.72563, 'auc': 0.98495}
test: {'epoch': 44, 'time_epoch': 0.53441, 'loss': 1.63215494, 'lr': 0, 'params': 240303, 'time_iter': 0.53441, 'accuracy': 0.82275, 'f1': 0.72563, 'auc': 0.98495}
> Epoch 44: took 3.2s (avg 2.4s) | Best so far: epoch 44	train_loss: 1.6366 train_accuracy: 0.8150	val_loss: 1.6322 val_accuracy: 0.8227	test_loss: 1.6322 test_accuracy: 0.8227
train: {'epoch': 45, 'time_epoch': 1.98704, 'eta': 115.59688, 'eta_hours': 0.03211, 'loss': 1.6323421, 'lr': 0.00033551, 'params': 240303, 'time_iter': 1.98704, 'accuracy': 0.82422, 'f1': 0.72221, 'auc': 0.98573}
train: {'epoch': 46, 'time_epoch': 2.0246, 'eta': 113.3253, 'eta_hours': 0.03148, 'loss': 1.62788856, 'lr': 0.00032725, 'params': 240303, 'time_iter': 2.0246, 'accuracy': 0.83641, 'f1': 0.73429, 'auc': 0.9876}
train: {'epoch': 47, 'time_epoch': 1.98817, 'eta': 111.02454, 'eta_hours': 0.03084, 'loss': 1.62398922, 'lr': 0.00031891, 'params': 240303, 'time_iter': 1.98817, 'accuracy': 0.84638, 'f1': 0.74775, 'auc': 0.98898}
train: {'epoch': 48, 'time_epoch': 2.01733, 'eta': 108.76689, 'eta_hours': 0.03021, 'loss': 1.61997998, 'lr': 0.00031048, 'params': 240303, 'time_iter': 2.01733, 'accuracy': 0.8534, 'f1': 0.75755, 'auc': 0.98754}
train: {'epoch': 49, 'time_epoch': 1.99614, 'eta': 106.49766, 'eta_hours': 0.02958, 'loss': 1.61617744, 'lr': 0.00030198, 'params': 240303, 'time_iter': 1.99614, 'accuracy': 0.86004, 'f1': 0.76074, 'auc': 0.98743}
val: {'epoch': 49, 'time_epoch': 0.58505, 'loss': 1.6121136, 'lr': 0, 'params': 240303, 'time_iter': 0.58505, 'accuracy': 0.86004, 'f1': 0.76723, 'auc': 0.98701}
test: {'epoch': 49, 'time_epoch': 0.53846, 'loss': 1.6121136, 'lr': 0, 'params': 240303, 'time_iter': 0.53846, 'accuracy': 0.86004, 'f1': 0.76723, 'auc': 0.98701}
> Epoch 49: took 3.2s (avg 2.4s) | Best so far: epoch 49	train_loss: 1.6162 train_accuracy: 0.8600	val_loss: 1.6121 val_accuracy: 0.8600	test_loss: 1.6121 test_accuracy: 0.8600
train: {'epoch': 50, 'time_epoch': 2.12379, 'eta': 104.36179, 'eta_hours': 0.02899, 'loss': 1.61211991, 'lr': 0.00029341, 'params': 240303, 'time_iter': 2.12379, 'accuracy': 0.86448, 'f1': 0.76848, 'auc': 0.98684}
train: {'epoch': 51, 'time_epoch': 2.05003, 'eta': 102.15829, 'eta_hours': 0.02838, 'loss': 1.60806179, 'lr': 0.00028479, 'params': 240303, 'time_iter': 2.05003, 'accuracy': 0.87149, 'f1': 0.77533, 'auc': 0.98911}
train: {'epoch': 52, 'time_epoch': 2.02621, 'eta': 99.93946, 'eta_hours': 0.02776, 'loss': 1.60521865, 'lr': 0.00027613, 'params': 240303, 'time_iter': 2.02621, 'accuracy': 0.87629, 'f1': 0.77989, 'auc': 0.98961}
train: {'epoch': 53, 'time_epoch': 2.0121, 'eta': 97.71574, 'eta_hours': 0.02714, 'loss': 1.60110414, 'lr': 0.00026744, 'params': 240303, 'time_iter': 2.0121, 'accuracy': 0.88552, 'f1': 0.78959, 'auc': 0.98887}
train: {'epoch': 54, 'time_epoch': 2.20789, 'eta': 95.65991, 'eta_hours': 0.02657, 'loss': 1.59873974, 'lr': 0.00025872, 'params': 240303, 'time_iter': 2.20789, 'accuracy': 0.88774, 'f1': 0.79165, 'auc': 0.98982}
val: {'epoch': 54, 'time_epoch': 0.70919, 'loss': 1.59514487, 'lr': 0, 'params': 240303, 'time_iter': 0.70919, 'accuracy': 0.88368, 'f1': 0.79202, 'auc': 0.98874}
test: {'epoch': 54, 'time_epoch': 0.59995, 'loss': 1.59514487, 'lr': 0, 'params': 240303, 'time_iter': 0.59995, 'accuracy': 0.88368, 'f1': 0.79202, 'auc': 0.98874}
> Epoch 54: took 3.6s (avg 2.4s) | Best so far: epoch 54	train_loss: 1.5987 train_accuracy: 0.8877	val_loss: 1.5951 val_accuracy: 0.8837	test_loss: 1.5951 test_accuracy: 0.8837
train: {'epoch': 55, 'time_epoch': 2.04303, 'eta': 93.46912, 'eta_hours': 0.02596, 'loss': 1.59539187, 'lr': 0.00025, 'params': 240303, 'time_iter': 2.04303, 'accuracy': 0.88774, 'f1': 0.79238, 'auc': 0.98908}
train: {'epoch': 56, 'time_epoch': 2.01653, 'eta': 91.26352, 'eta_hours': 0.02535, 'loss': 1.592816, 'lr': 0.00024128, 'params': 240303, 'time_iter': 2.01653, 'accuracy': 0.8918, 'f1': 0.79912, 'auc': 0.99017}
train: {'epoch': 57, 'time_epoch': 1.99076, 'eta': 89.04578, 'eta_hours': 0.02473, 'loss': 1.58998168, 'lr': 0.00023256, 'params': 240303, 'time_iter': 1.99076, 'accuracy': 0.89402, 'f1': 0.80717, 'auc': 0.99044}
train: {'epoch': 58, 'time_epoch': 2.00653, 'eta': 86.84669, 'eta_hours': 0.02412, 'loss': 1.5872581, 'lr': 0.00022387, 'params': 240303, 'time_iter': 2.00653, 'accuracy': 0.89956, 'f1': 0.81174, 'auc': 0.99027}
train: {'epoch': 59, 'time_epoch': 2.01672, 'eta': 84.66082, 'eta_hours': 0.02352, 'loss': 1.58492267, 'lr': 0.00021521, 'params': 240303, 'time_iter': 2.01672, 'accuracy': 0.89771, 'f1': 0.81114, 'auc': 0.99148}
val: {'epoch': 59, 'time_epoch': 0.59587, 'loss': 1.58033693, 'lr': 0, 'params': 240303, 'time_iter': 0.59587, 'accuracy': 0.9014, 'f1': 0.81137, 'auc': 0.99009}
test: {'epoch': 59, 'time_epoch': 0.53561, 'loss': 1.58033693, 'lr': 0, 'params': 240303, 'time_iter': 0.53561, 'accuracy': 0.9014, 'f1': 0.81137, 'auc': 0.99009}
> Epoch 59: took 3.2s (avg 2.4s) | Best so far: epoch 59	train_loss: 1.5849 train_accuracy: 0.8977	val_loss: 1.5803 val_accuracy: 0.9014	test_loss: 1.5803 test_accuracy: 0.9014
train: {'epoch': 60, 'time_epoch': 1.98373, 'eta': 82.4594, 'eta_hours': 0.02291, 'loss': 1.58174324, 'lr': 0.00020659, 'params': 240303, 'time_iter': 1.98373, 'accuracy': 0.90288, 'f1': 0.81797, 'auc': 0.99174}
train: {'epoch': 61, 'time_epoch': 2.05103, 'eta': 80.30625, 'eta_hours': 0.02231, 'loss': 1.5796479, 'lr': 0.00019802, 'params': 240303, 'time_iter': 2.05103, 'accuracy': 0.90066, 'f1': 0.81811, 'auc': 0.99144}
train: {'epoch': 62, 'time_epoch': 2.00856, 'eta': 78.1314, 'eta_hours': 0.0217, 'loss': 1.57736063, 'lr': 0.00018952, 'params': 240303, 'time_iter': 2.00856, 'accuracy': 0.90731, 'f1': 0.82452, 'auc': 0.99244}
train: {'epoch': 63, 'time_epoch': 2.06303, 'eta': 75.99238, 'eta_hours': 0.02111, 'loss': 1.57566082, 'lr': 0.00018109, 'params': 240303, 'time_iter': 2.06303, 'accuracy': 0.90436, 'f1': 0.82415, 'auc': 0.99188}
train: {'epoch': 64, 'time_epoch': 2.03506, 'eta': 73.84065, 'eta_hours': 0.02051, 'loss': 1.57340229, 'lr': 0.00017275, 'params': 240303, 'time_iter': 2.03506, 'accuracy': 0.91027, 'f1': 0.83102, 'auc': 0.99169}
val: {'epoch': 64, 'time_epoch': 0.58918, 'loss': 1.56849027, 'lr': 0, 'params': 240303, 'time_iter': 0.58918, 'accuracy': 0.91211, 'f1': 0.83004, 'auc': 0.99174}
test: {'epoch': 64, 'time_epoch': 0.56512, 'loss': 1.56849027, 'lr': 0, 'params': 240303, 'time_iter': 0.56512, 'accuracy': 0.91211, 'f1': 0.83004, 'auc': 0.99174}
> Epoch 64: took 3.2s (avg 2.4s) | Best so far: epoch 64	train_loss: 1.5734 train_accuracy: 0.9103	val_loss: 1.5685 val_accuracy: 0.9121	test_loss: 1.5685 test_accuracy: 0.9121
train: {'epoch': 65, 'time_epoch': 1.95458, 'eta': 71.65099, 'eta_hours': 0.0199, 'loss': 1.57106543, 'lr': 0.00016449, 'params': 240303, 'time_iter': 1.95458, 'accuracy': 0.91211, 'f1': 0.83446, 'auc': 0.99206}
train: {'epoch': 66, 'time_epoch': 2.15187, 'eta': 69.56551, 'eta_hours': 0.01932, 'loss': 1.56989741, 'lr': 0.00015635, 'params': 240303, 'time_iter': 2.15187, 'accuracy': 0.91248, 'f1': 0.84444, 'auc': 0.99248}
train: {'epoch': 67, 'time_epoch': 2.2768, 'eta': 67.53688, 'eta_hours': 0.01876, 'loss': 1.56807625, 'lr': 0.00014832, 'params': 240303, 'time_iter': 2.2768, 'accuracy': 0.91174, 'f1': 0.84659, 'auc': 0.99241}
train: {'epoch': 68, 'time_epoch': 2.08032, 'eta': 65.41278, 'eta_hours': 0.01817, 'loss': 1.56675196, 'lr': 0.00014041, 'params': 240303, 'time_iter': 2.08032, 'accuracy': 0.9147, 'f1': 0.8479, 'auc': 0.99254}
train: {'epoch': 69, 'time_epoch': 2.0193, 'eta': 63.26378, 'eta_hours': 0.01757, 'loss': 1.56489813, 'lr': 0.00013263, 'params': 240303, 'time_iter': 2.0193, 'accuracy': 0.92061, 'f1': 0.86014, 'auc': 0.99242}
val: {'epoch': 69, 'time_epoch': 0.59156, 'loss': 1.56020486, 'lr': 0, 'params': 240303, 'time_iter': 0.59156, 'accuracy': 0.92097, 'f1': 0.85541, 'auc': 0.99288}
test: {'epoch': 69, 'time_epoch': 0.5405, 'loss': 1.56020486, 'lr': 0, 'params': 240303, 'time_iter': 0.5405, 'accuracy': 0.92097, 'f1': 0.85541, 'auc': 0.99288}
> Epoch 69: took 3.2s (avg 2.4s) | Best so far: epoch 69	train_loss: 1.5649 train_accuracy: 0.9206	val_loss: 1.5602 val_accuracy: 0.9210	test_loss: 1.5602 test_accuracy: 0.9210
train: {'epoch': 70, 'time_epoch': 2.06768, 'eta': 61.1382, 'eta_hours': 0.01698, 'loss': 1.56337905, 'lr': 0.000125, 'params': 240303, 'time_iter': 2.06768, 'accuracy': 0.92356, 'f1': 0.87272, 'auc': 0.99318}
train: {'epoch': 71, 'time_epoch': 2.0767, 'eta': 59.01773, 'eta_hours': 0.01639, 'loss': 1.56303537, 'lr': 0.00011752, 'params': 240303, 'time_iter': 2.0767, 'accuracy': 0.92504, 'f1': 0.87495, 'auc': 0.99353}
train: {'epoch': 72, 'time_epoch': 2.14842, 'eta': 56.92499, 'eta_hours': 0.01581, 'loss': 1.56116045, 'lr': 0.0001102, 'params': 240303, 'time_iter': 2.14842, 'accuracy': 0.93722, 'f1': 0.90692, 'auc': 0.99346}
train: {'epoch': 73, 'time_epoch': 2.0246, 'eta': 54.78724, 'eta_hours': 0.01522, 'loss': 1.56000376, 'lr': 0.00010305, 'params': 240303, 'time_iter': 2.0246, 'accuracy': 0.93316, 'f1': 0.89551, 'auc': 0.99261}
train: {'epoch': 74, 'time_epoch': 2.03001, 'eta': 52.6543, 'eta_hours': 0.01463, 'loss': 1.55847371, 'lr': 9.608e-05, 'params': 240303, 'time_iter': 2.03001, 'accuracy': 0.93316, 'f1': 0.89475, 'auc': 0.9934}
val: {'epoch': 74, 'time_epoch': 0.57456, 'loss': 1.55438638, 'lr': 0, 'params': 240303, 'time_iter': 0.57456, 'accuracy': 0.93538, 'f1': 0.89644, 'auc': 0.99357}
test: {'epoch': 74, 'time_epoch': 0.54746, 'loss': 1.55438638, 'lr': 0, 'params': 240303, 'time_iter': 0.54746, 'accuracy': 0.93538, 'f1': 0.89644, 'auc': 0.99357}
> Epoch 74: took 3.2s (avg 2.4s) | Best so far: epoch 74	train_loss: 1.5585 train_accuracy: 0.9332	val_loss: 1.5544 val_accuracy: 0.9354	test_loss: 1.5544 test_accuracy: 0.9354
train: {'epoch': 75, 'time_epoch': 1.97894, 'eta': 50.50795, 'eta_hours': 0.01403, 'loss': 1.55784869, 'lr': 8.93e-05, 'params': 240303, 'time_iter': 1.97894, 'accuracy': 0.93907, 'f1': 0.90831, 'auc': 0.99367}
train: {'epoch': 76, 'time_epoch': 2.01588, 'eta': 48.37698, 'eta_hours': 0.01344, 'loss': 1.55700576, 'lr': 8.272e-05, 'params': 240303, 'time_iter': 2.01588, 'accuracy': 0.94018, 'f1': 0.91006, 'auc': 0.99303}
train: {'epoch': 77, 'time_epoch': 2.0122, 'eta': 46.24793, 'eta_hours': 0.01285, 'loss': 1.55614567, 'lr': 7.634e-05, 'params': 240303, 'time_iter': 2.0122, 'accuracy': 0.94055, 'f1': 0.91238, 'auc': 0.99341}
train: {'epoch': 78, 'time_epoch': 2.03482, 'eta': 44.12784, 'eta_hours': 0.01226, 'loss': 1.55586004, 'lr': 7.017e-05, 'params': 240303, 'time_iter': 2.03482, 'accuracy': 0.9483, 'f1': 0.92681, 'auc': 0.99428}
train: {'epoch': 79, 'time_epoch': 2.02249, 'eta': 42.00681, 'eta_hours': 0.01167, 'loss': 1.55445313, 'lr': 6.421e-05, 'params': 240303, 'time_iter': 2.02249, 'accuracy': 0.9435, 'f1': 0.91733, 'auc': 0.99466}
val: {'epoch': 79, 'time_epoch': 0.58711, 'loss': 1.55039001, 'lr': 0, 'params': 240303, 'time_iter': 0.58711, 'accuracy': 0.94978, 'f1': 0.92861, 'auc': 0.99413}
test: {'epoch': 79, 'time_epoch': 0.53776, 'loss': 1.55039001, 'lr': 0, 'params': 240303, 'time_iter': 0.53776, 'accuracy': 0.94978, 'f1': 0.92861, 'auc': 0.99413}
> Epoch 79: took 3.2s (avg 2.4s) | Best so far: epoch 79	train_loss: 1.5545 train_accuracy: 0.9435	val_loss: 1.5504 val_accuracy: 0.9498	test_loss: 1.5504 test_accuracy: 0.9498
train: {'epoch': 80, 'time_epoch': 2.24177, 'eta': 39.93964, 'eta_hours': 0.01109, 'loss': 1.55457747, 'lr': 5.849e-05, 'params': 240303, 'time_iter': 2.24177, 'accuracy': 0.94793, 'f1': 0.92628, 'auc': 0.99409}
train: {'epoch': 81, 'time_epoch': 2.02653, 'eta': 37.82097, 'eta_hours': 0.01051, 'loss': 1.55368149, 'lr': 5.3e-05, 'params': 240303, 'time_iter': 2.02653, 'accuracy': 0.94645, 'f1': 0.92223, 'auc': 0.99411}
train: {'epoch': 82, 'time_epoch': 2.0061, 'eta': 35.70034, 'eta_hours': 0.00992, 'loss': 1.55295324, 'lr': 4.775e-05, 'params': 240303, 'time_iter': 2.0061, 'accuracy': 0.9435, 'f1': 0.91756, 'auc': 0.9938}
train: {'epoch': 83, 'time_epoch': 1.99661, 'eta': 33.58062, 'eta_hours': 0.00933, 'loss': 1.55326986, 'lr': 4.274e-05, 'params': 240303, 'time_iter': 1.99661, 'accuracy': 0.94276, 'f1': 0.91529, 'auc': 0.994}
train: {'epoch': 84, 'time_epoch': 2.04571, 'eta': 31.47246, 'eta_hours': 0.00874, 'loss': 1.55225205, 'lr': 3.799e-05, 'params': 240303, 'time_iter': 2.04571, 'accuracy': 0.95421, 'f1': 0.93541, 'auc': 0.9932}
val: {'epoch': 84, 'time_epoch': 0.59443, 'loss': 1.54792571, 'lr': 0, 'params': 240303, 'time_iter': 0.59443, 'accuracy': 0.95716, 'f1': 0.94288, 'auc': 0.99439}
test: {'epoch': 84, 'time_epoch': 0.53407, 'loss': 1.54792571, 'lr': 0, 'params': 240303, 'time_iter': 0.53407, 'accuracy': 0.95716, 'f1': 0.94288, 'auc': 0.99439}
> Epoch 84: took 3.2s (avg 2.4s) | Best so far: epoch 84	train_loss: 1.5523 train_accuracy: 0.9542	val_loss: 1.5479 val_accuracy: 0.9572	test_loss: 1.5479 test_accuracy: 0.9572
train: {'epoch': 85, 'time_epoch': 1.98053, 'eta': 29.35515, 'eta_hours': 0.00815, 'loss': 1.55191851, 'lr': 3.349e-05, 'params': 240303, 'time_iter': 1.98053, 'accuracy': 0.95052, 'f1': 0.93156, 'auc': 0.99385}
train: {'epoch': 86, 'time_epoch': 2.02815, 'eta': 27.2481, 'eta_hours': 0.00757, 'loss': 1.55156815, 'lr': 2.926e-05, 'params': 240303, 'time_iter': 2.02815, 'accuracy': 0.95606, 'f1': 0.94053, 'auc': 0.99394}
train: {'epoch': 87, 'time_epoch': 2.01978, 'eta': 25.14169, 'eta_hours': 0.00698, 'loss': 1.55131805, 'lr': 2.53e-05, 'params': 240303, 'time_iter': 2.01978, 'accuracy': 0.94682, 'f1': 0.92298, 'auc': 0.99463}
train: {'epoch': 88, 'time_epoch': 1.99322, 'eta': 23.03396, 'eta_hours': 0.0064, 'loss': 1.55132484, 'lr': 2.161e-05, 'params': 240303, 'time_iter': 1.99322, 'accuracy': 0.9531, 'f1': 0.93814, 'auc': 0.99485}
train: {'epoch': 89, 'time_epoch': 2.01625, 'eta': 20.93132, 'eta_hours': 0.00581, 'loss': 1.55048108, 'lr': 1.82e-05, 'params': 240303, 'time_iter': 2.01625, 'accuracy': 0.95495, 'f1': 0.93928, 'auc': 0.99454}
val: {'epoch': 89, 'time_epoch': 0.59319, 'loss': 1.54668093, 'lr': 0, 'params': 240303, 'time_iter': 0.59319, 'accuracy': 0.96049, 'f1': 0.94861, 'auc': 0.99456}
test: {'epoch': 89, 'time_epoch': 0.52603, 'loss': 1.54668093, 'lr': 0, 'params': 240303, 'time_iter': 0.52603, 'accuracy': 0.96049, 'f1': 0.94861, 'auc': 0.99456}
> Epoch 89: took 3.2s (avg 2.4s) | Best so far: epoch 89	train_loss: 1.5505 train_accuracy: 0.9549	val_loss: 1.5467 val_accuracy: 0.9605	test_loss: 1.5467 test_accuracy: 0.9605
train: {'epoch': 90, 'time_epoch': 1.96551, 'eta': 18.82557, 'eta_hours': 0.00523, 'loss': 1.55135298, 'lr': 1.508e-05, 'params': 240303, 'time_iter': 1.96551, 'accuracy': 0.94682, 'f1': 0.92616, 'auc': 0.99411}
train: {'epoch': 91, 'time_epoch': 2.02417, 'eta': 16.72796, 'eta_hours': 0.00465, 'loss': 1.5502547, 'lr': 1.224e-05, 'params': 240303, 'time_iter': 2.02417, 'accuracy': 0.95495, 'f1': 0.93714, 'auc': 0.99457}
train: {'epoch': 92, 'time_epoch': 2.0336, 'eta': 14.63265, 'eta_hours': 0.00406, 'loss': 1.55032957, 'lr': 9.68e-06, 'params': 240303, 'time_iter': 2.0336, 'accuracy': 0.95643, 'f1': 0.94185, 'auc': 0.99331}
train: {'epoch': 93, 'time_epoch': 2.30326, 'eta': 12.55586, 'eta_hours': 0.00349, 'loss': 1.55079067, 'lr': 7.43e-06, 'params': 240303, 'time_iter': 2.30326, 'accuracy': 0.95273, 'f1': 0.93791, 'auc': 0.99326}
train: {'epoch': 94, 'time_epoch': 2.12792, 'eta': 10.46507, 'eta_hours': 0.00291, 'loss': 1.55007637, 'lr': 5.46e-06, 'params': 240303, 'time_iter': 2.12792, 'accuracy': 0.95273, 'f1': 0.93443, 'auc': 0.9942}
val: {'epoch': 94, 'time_epoch': 0.58712, 'loss': 1.54618132, 'lr': 0, 'params': 240303, 'time_iter': 0.58712, 'accuracy': 0.9616, 'f1': 0.95026, 'auc': 0.99463}
test: {'epoch': 94, 'time_epoch': 0.53943, 'loss': 1.54618132, 'lr': 0, 'params': 240303, 'time_iter': 0.53943, 'accuracy': 0.9616, 'f1': 0.95026, 'auc': 0.99463}
> Epoch 94: took 3.3s (avg 2.4s) | Best so far: epoch 94	train_loss: 1.5501 train_accuracy: 0.9527	val_loss: 1.5462 val_accuracy: 0.9616	test_loss: 1.5462 test_accuracy: 0.9616
train: {'epoch': 95, 'time_epoch': 1.99783, 'eta': 8.36809, 'eta_hours': 0.00232, 'loss': 1.55068934, 'lr': 3.8e-06, 'params': 240303, 'time_iter': 1.99783, 'accuracy': 0.95679, 'f1': 0.94293, 'auc': 0.99427}
train: {'epoch': 96, 'time_epoch': 2.04074, 'eta': 6.27448, 'eta_hours': 0.00174, 'loss': 1.55087841, 'lr': 2.43e-06, 'params': 240303, 'time_iter': 2.04074, 'accuracy': 0.9435, 'f1': 0.91915, 'auc': 0.99372}
train: {'epoch': 97, 'time_epoch': 2.01342, 'eta': 4.1814, 'eta_hours': 0.00116, 'loss': 1.54986846, 'lr': 1.37e-06, 'params': 240303, 'time_iter': 2.01342, 'accuracy': 0.95569, 'f1': 0.94061, 'auc': 0.99422}
train: {'epoch': 98, 'time_epoch': 2.02218, 'eta': 2.09001, 'eta_hours': 0.00058, 'loss': 1.55008221, 'lr': 6.1e-07, 'params': 240303, 'time_iter': 2.02218, 'accuracy': 0.95126, 'f1': 0.93117, 'auc': 0.99418}
train: {'epoch': 99, 'time_epoch': 2.00603, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 1.55018806, 'lr': 1.5e-07, 'params': 240303, 'time_iter': 2.00603, 'accuracy': 0.95162, 'f1': 0.93338, 'auc': 0.99419}
val: {'epoch': 99, 'time_epoch': 0.57636, 'loss': 1.54608274, 'lr': 0, 'params': 240303, 'time_iter': 0.57636, 'accuracy': 0.96123, 'f1': 0.94975, 'auc': 0.99462}
test: {'epoch': 99, 'time_epoch': 0.53935, 'loss': 1.54608274, 'lr': 0, 'params': 240303, 'time_iter': 0.53935, 'accuracy': 0.96123, 'f1': 0.94975, 'auc': 0.99462}
> Epoch 99: took 3.2s (avg 2.3s) | Best so far: epoch 94	train_loss: 1.5501 train_accuracy: 0.9527	val_loss: 1.5462 val_accuracy: 0.9616	test_loss: 1.5462 test_accuracy: 0.9616
Avg time per epoch: 2.35s
Total train loop time: 0.07h
Task done, results saved in results/cora/Cora-GPS/0
Results aggregated across runs saved in results/cora/Cora-GPS/agg
[*] All done: 2024-12-02 23:21:12.408432
